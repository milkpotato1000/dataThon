{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e1c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from scipy.stats import randint, uniform, loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa83b9b-abfb-4927-b974-a8a8c927f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/users_prep.csv\")\n",
    "data = data.drop(\"Unnamed: 0\", axis=1) \n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d3c221a-c859-4690-bcfd-5b0c8e5156a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>current_age</th>\n",
       "      <th>retirement_age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>birth_month</th>\n",
       "      <th>gender</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>...</th>\n",
       "      <th>W_avg_median_amount</th>\n",
       "      <th>W_avg_count_transaction</th>\n",
       "      <th>M_avg_min_amount</th>\n",
       "      <th>M_avg_max_amount</th>\n",
       "      <th>M_avg_mean_amount</th>\n",
       "      <th>M_avg_median_amount</th>\n",
       "      <th>M_avg_count_transaction</th>\n",
       "      <th>monthly_evg_unique_merchants</th>\n",
       "      <th>gap_sec</th>\n",
       "      <th>fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>825</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>1966</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.15</td>\n",
       "      <td>-117.76</td>\n",
       "      <td>29278</td>\n",
       "      <td>59696</td>\n",
       "      <td>...</td>\n",
       "      <td>71.547335</td>\n",
       "      <td>22.130350</td>\n",
       "      <td>2.589153</td>\n",
       "      <td>559.207627</td>\n",
       "      <td>80.417801</td>\n",
       "      <td>68.428941</td>\n",
       "      <td>96.398305</td>\n",
       "      <td>32.644068</td>\n",
       "      <td>18420.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1746</td>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>1966</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.74</td>\n",
       "      <td>37891</td>\n",
       "      <td>77254</td>\n",
       "      <td>...</td>\n",
       "      <td>64.614815</td>\n",
       "      <td>10.881323</td>\n",
       "      <td>2.200085</td>\n",
       "      <td>686.285932</td>\n",
       "      <td>79.696503</td>\n",
       "      <td>66.091822</td>\n",
       "      <td>47.398305</td>\n",
       "      <td>28.025424</td>\n",
       "      <td>37530.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1718</td>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>1938</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.02</td>\n",
       "      <td>-117.89</td>\n",
       "      <td>22681</td>\n",
       "      <td>33483</td>\n",
       "      <td>...</td>\n",
       "      <td>31.666401</td>\n",
       "      <td>50.365759</td>\n",
       "      <td>0.978983</td>\n",
       "      <td>412.923729</td>\n",
       "      <td>33.051507</td>\n",
       "      <td>32.344788</td>\n",
       "      <td>219.389831</td>\n",
       "      <td>36.983051</td>\n",
       "      <td>7380.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>708</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>1957</td>\n",
       "      <td>1</td>\n",
       "      <td>Female</td>\n",
       "      <td>40.71</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>163145</td>\n",
       "      <td>249925</td>\n",
       "      <td>...</td>\n",
       "      <td>61.903687</td>\n",
       "      <td>16.889105</td>\n",
       "      <td>5.520763</td>\n",
       "      <td>1576.102458</td>\n",
       "      <td>125.770742</td>\n",
       "      <td>58.425551</td>\n",
       "      <td>73.567797</td>\n",
       "      <td>33.559322</td>\n",
       "      <td>20040.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1164</td>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>1976</td>\n",
       "      <td>9</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.76</td>\n",
       "      <td>-122.44</td>\n",
       "      <td>53797</td>\n",
       "      <td>109687</td>\n",
       "      <td>...</td>\n",
       "      <td>87.131060</td>\n",
       "      <td>17.951362</td>\n",
       "      <td>4.826525</td>\n",
       "      <td>817.697966</td>\n",
       "      <td>96.408370</td>\n",
       "      <td>87.651398</td>\n",
       "      <td>78.194915</td>\n",
       "      <td>36.466102</td>\n",
       "      <td>20160.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  current_age  retirement_age  birth_year  birth_month  gender  \\\n",
       "0   825           53              66        1966           11  Female   \n",
       "1  1746           53              68        1966           12  Female   \n",
       "2  1718           81              67        1938           11  Female   \n",
       "3   708           63              63        1957            1  Female   \n",
       "4  1164           43              70        1976            9    Male   \n",
       "\n",
       "   latitude  longitude  per_capita_income  yearly_income  ...  \\\n",
       "0     34.15    -117.76              29278          59696  ...   \n",
       "1     40.76     -73.74              37891          77254  ...   \n",
       "2     34.02    -117.89              22681          33483  ...   \n",
       "3     40.71     -73.99             163145         249925  ...   \n",
       "4     37.76    -122.44              53797         109687  ...   \n",
       "\n",
       "   W_avg_median_amount  W_avg_count_transaction  M_avg_min_amount  \\\n",
       "0            71.547335                22.130350          2.589153   \n",
       "1            64.614815                10.881323          2.200085   \n",
       "2            31.666401                50.365759          0.978983   \n",
       "3            61.903687                16.889105          5.520763   \n",
       "4            87.131060                17.951362          4.826525   \n",
       "\n",
       "   M_avg_max_amount  M_avg_mean_amount  M_avg_median_amount  \\\n",
       "0        559.207627          80.417801            68.428941   \n",
       "1        686.285932          79.696503            66.091822   \n",
       "2        412.923729          33.051507            32.344788   \n",
       "3       1576.102458         125.770742            58.425551   \n",
       "4        817.697966          96.408370            87.651398   \n",
       "\n",
       "   M_avg_count_transaction monthly_evg_unique_merchants  gap_sec  fraud_risk  \n",
       "0                96.398305                    32.644068  18420.0         0.0  \n",
       "1                47.398305                    28.025424  37530.0         1.0  \n",
       "2               219.389831                    36.983051   7380.0         1.0  \n",
       "3                73.567797                    33.559322  20040.0         0.0  \n",
       "4                78.194915                    36.466102  20160.0         0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "803f480c-ed14-4dbc-bbff-727ff8816bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1219 entries, 0 to 1997\n",
      "Data columns (total 32 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   id                            1219 non-null   int64  \n",
      " 1   current_age                   1219 non-null   int64  \n",
      " 2   retirement_age                1219 non-null   int64  \n",
      " 3   birth_year                    1219 non-null   int64  \n",
      " 4   birth_month                   1219 non-null   int64  \n",
      " 5   gender                        1219 non-null   object \n",
      " 6   latitude                      1219 non-null   float64\n",
      " 7   longitude                     1219 non-null   float64\n",
      " 8   per_capita_income             1219 non-null   int64  \n",
      " 9   yearly_income                 1219 non-null   int64  \n",
      " 10  total_debt                    1219 non-null   int64  \n",
      " 11  credit_score                  1219 non-null   int64  \n",
      " 12  num_credit_cards              1219 non-null   int64  \n",
      " 13  fraud_count                   1219 non-null   float64\n",
      " 14  chip_ratio                    1219 non-null   float64\n",
      " 15  online_ratio                  1219 non-null   float64\n",
      " 16  swipe_ratio                   1219 non-null   float64\n",
      " 17  most_prefer                   1219 non-null   object \n",
      " 18  least_prefer                  1219 non-null   object \n",
      " 19  W_avg_min_amount              1219 non-null   float64\n",
      " 20  W_avg_max_amount              1219 non-null   float64\n",
      " 21  W_avg_mean_amount             1219 non-null   float64\n",
      " 22  W_avg_median_amount           1219 non-null   float64\n",
      " 23  W_avg_count_transaction       1219 non-null   float64\n",
      " 24  M_avg_min_amount              1219 non-null   float64\n",
      " 25  M_avg_max_amount              1219 non-null   float64\n",
      " 26  M_avg_mean_amount             1219 non-null   float64\n",
      " 27  M_avg_median_amount           1219 non-null   float64\n",
      " 28  M_avg_count_transaction       1219 non-null   float64\n",
      " 29  monthly_evg_unique_merchants  1219 non-null   float64\n",
      " 30  gap_sec                       1219 non-null   float64\n",
      " 31  fraud_risk                    1219 non-null   float64\n",
      "dtypes: float64(19), int64(10), object(3)\n",
      "memory usage: 314.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485b03ee-442f-416f-83cf-35ad81725695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 (예시)\n",
    "X = data.drop(columns=['id', 'fraud_count', 'fraud_risk', 'birth_month', 'longitude', 'latitude'])\n",
    "y = data['fraud_risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a736379f-03bd-4087-bb04-fcd607e8245f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_age</th>\n",
       "      <th>retirement_age</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>gender</th>\n",
       "      <th>per_capita_income</th>\n",
       "      <th>yearly_income</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>num_credit_cards</th>\n",
       "      <th>chip_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>W_avg_mean_amount</th>\n",
       "      <th>W_avg_median_amount</th>\n",
       "      <th>W_avg_count_transaction</th>\n",
       "      <th>M_avg_min_amount</th>\n",
       "      <th>M_avg_max_amount</th>\n",
       "      <th>M_avg_mean_amount</th>\n",
       "      <th>M_avg_median_amount</th>\n",
       "      <th>M_avg_count_transaction</th>\n",
       "      <th>monthly_evg_unique_merchants</th>\n",
       "      <th>gap_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>1966</td>\n",
       "      <td>Female</td>\n",
       "      <td>29278</td>\n",
       "      <td>59696</td>\n",
       "      <td>127613</td>\n",
       "      <td>787</td>\n",
       "      <td>5</td>\n",
       "      <td>0.231560</td>\n",
       "      <td>...</td>\n",
       "      <td>81.057181</td>\n",
       "      <td>71.547335</td>\n",
       "      <td>22.130350</td>\n",
       "      <td>2.589153</td>\n",
       "      <td>559.207627</td>\n",
       "      <td>80.417801</td>\n",
       "      <td>68.428941</td>\n",
       "      <td>96.398305</td>\n",
       "      <td>32.644068</td>\n",
       "      <td>18420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>68</td>\n",
       "      <td>1966</td>\n",
       "      <td>Female</td>\n",
       "      <td>37891</td>\n",
       "      <td>77254</td>\n",
       "      <td>191349</td>\n",
       "      <td>701</td>\n",
       "      <td>5</td>\n",
       "      <td>0.434114</td>\n",
       "      <td>...</td>\n",
       "      <td>79.726211</td>\n",
       "      <td>64.614815</td>\n",
       "      <td>10.881323</td>\n",
       "      <td>2.200085</td>\n",
       "      <td>686.285932</td>\n",
       "      <td>79.696503</td>\n",
       "      <td>66.091822</td>\n",
       "      <td>47.398305</td>\n",
       "      <td>28.025424</td>\n",
       "      <td>37530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>67</td>\n",
       "      <td>1938</td>\n",
       "      <td>Female</td>\n",
       "      <td>22681</td>\n",
       "      <td>33483</td>\n",
       "      <td>196</td>\n",
       "      <td>698</td>\n",
       "      <td>5</td>\n",
       "      <td>0.190590</td>\n",
       "      <td>...</td>\n",
       "      <td>33.045918</td>\n",
       "      <td>31.666401</td>\n",
       "      <td>50.365759</td>\n",
       "      <td>0.978983</td>\n",
       "      <td>412.923729</td>\n",
       "      <td>33.051507</td>\n",
       "      <td>32.344788</td>\n",
       "      <td>219.389831</td>\n",
       "      <td>36.983051</td>\n",
       "      <td>7380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "      <td>1957</td>\n",
       "      <td>Female</td>\n",
       "      <td>163145</td>\n",
       "      <td>249925</td>\n",
       "      <td>202328</td>\n",
       "      <td>722</td>\n",
       "      <td>4</td>\n",
       "      <td>0.429674</td>\n",
       "      <td>...</td>\n",
       "      <td>126.519642</td>\n",
       "      <td>61.903687</td>\n",
       "      <td>16.889105</td>\n",
       "      <td>5.520763</td>\n",
       "      <td>1576.102458</td>\n",
       "      <td>125.770742</td>\n",
       "      <td>58.425551</td>\n",
       "      <td>73.567797</td>\n",
       "      <td>33.559322</td>\n",
       "      <td>20040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>70</td>\n",
       "      <td>1976</td>\n",
       "      <td>Male</td>\n",
       "      <td>53797</td>\n",
       "      <td>109687</td>\n",
       "      <td>183855</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "      <td>0.389509</td>\n",
       "      <td>...</td>\n",
       "      <td>96.090390</td>\n",
       "      <td>87.131060</td>\n",
       "      <td>17.951362</td>\n",
       "      <td>4.826525</td>\n",
       "      <td>817.697966</td>\n",
       "      <td>96.408370</td>\n",
       "      <td>87.651398</td>\n",
       "      <td>78.194915</td>\n",
       "      <td>36.466102</td>\n",
       "      <td>20160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>31</td>\n",
       "      <td>72</td>\n",
       "      <td>1988</td>\n",
       "      <td>Female</td>\n",
       "      <td>13194</td>\n",
       "      <td>26900</td>\n",
       "      <td>74083</td>\n",
       "      <td>758</td>\n",
       "      <td>2</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>...</td>\n",
       "      <td>15.993225</td>\n",
       "      <td>15.823071</td>\n",
       "      <td>29.737828</td>\n",
       "      <td>11.146290</td>\n",
       "      <td>248.217581</td>\n",
       "      <td>22.636976</td>\n",
       "      <td>22.632258</td>\n",
       "      <td>128.064516</td>\n",
       "      <td>23.064516</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>1934</td>\n",
       "      <td>Female</td>\n",
       "      <td>19025</td>\n",
       "      <td>35270</td>\n",
       "      <td>1769</td>\n",
       "      <td>731</td>\n",
       "      <td>6</td>\n",
       "      <td>0.411307</td>\n",
       "      <td>...</td>\n",
       "      <td>45.547766</td>\n",
       "      <td>40.084776</td>\n",
       "      <td>10.254864</td>\n",
       "      <td>6.469746</td>\n",
       "      <td>325.680424</td>\n",
       "      <td>44.708037</td>\n",
       "      <td>39.516822</td>\n",
       "      <td>44.669492</td>\n",
       "      <td>22.067797</td>\n",
       "      <td>33480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>32</td>\n",
       "      <td>70</td>\n",
       "      <td>1987</td>\n",
       "      <td>Male</td>\n",
       "      <td>23550</td>\n",
       "      <td>48010</td>\n",
       "      <td>87837</td>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.306986</td>\n",
       "      <td>...</td>\n",
       "      <td>23.130076</td>\n",
       "      <td>2.292130</td>\n",
       "      <td>22.447471</td>\n",
       "      <td>0.759576</td>\n",
       "      <td>538.056102</td>\n",
       "      <td>23.209078</td>\n",
       "      <td>1.863475</td>\n",
       "      <td>97.779661</td>\n",
       "      <td>18.610169</td>\n",
       "      <td>18960.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>1957</td>\n",
       "      <td>Female</td>\n",
       "      <td>24218</td>\n",
       "      <td>49378</td>\n",
       "      <td>104480</td>\n",
       "      <td>740</td>\n",
       "      <td>4</td>\n",
       "      <td>0.257192</td>\n",
       "      <td>...</td>\n",
       "      <td>39.990010</td>\n",
       "      <td>18.858191</td>\n",
       "      <td>20.219844</td>\n",
       "      <td>1.700254</td>\n",
       "      <td>470.129153</td>\n",
       "      <td>40.469902</td>\n",
       "      <td>17.507881</td>\n",
       "      <td>88.076271</td>\n",
       "      <td>32.135593</td>\n",
       "      <td>18240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>47</td>\n",
       "      <td>67</td>\n",
       "      <td>1973</td>\n",
       "      <td>Female</td>\n",
       "      <td>15175</td>\n",
       "      <td>30942</td>\n",
       "      <td>71066</td>\n",
       "      <td>779</td>\n",
       "      <td>3</td>\n",
       "      <td>0.471843</td>\n",
       "      <td>...</td>\n",
       "      <td>30.104664</td>\n",
       "      <td>7.217393</td>\n",
       "      <td>22.801556</td>\n",
       "      <td>1.327288</td>\n",
       "      <td>397.126017</td>\n",
       "      <td>30.080759</td>\n",
       "      <td>4.976441</td>\n",
       "      <td>99.322034</td>\n",
       "      <td>29.991525</td>\n",
       "      <td>11220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1219 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      current_age  retirement_age  birth_year  gender  per_capita_income  \\\n",
       "0              53              66        1966  Female              29278   \n",
       "1              53              68        1966  Female              37891   \n",
       "2              81              67        1938  Female              22681   \n",
       "3              63              63        1957  Female             163145   \n",
       "4              43              70        1976    Male              53797   \n",
       "...           ...             ...         ...     ...                ...   \n",
       "1992           31              72        1988  Female              13194   \n",
       "1993           85              66        1934  Female              19025   \n",
       "1995           32              70        1987    Male              23550   \n",
       "1996           62              65        1957  Female              24218   \n",
       "1997           47              67        1973  Female              15175   \n",
       "\n",
       "      yearly_income  total_debt  credit_score  num_credit_cards  chip_ratio  \\\n",
       "0             59696      127613           787                 5    0.231560   \n",
       "1             77254      191349           701                 5    0.434114   \n",
       "2             33483         196           698                 5    0.190590   \n",
       "3            249925      202328           722                 4    0.429674   \n",
       "4            109687      183855           675                 1    0.389509   \n",
       "...             ...         ...           ...               ...         ...   \n",
       "1992          26900       74083           758                 2    0.908438   \n",
       "1993          35270        1769           731                 6    0.411307   \n",
       "1995          48010       87837           703                 3    0.306986   \n",
       "1996          49378      104480           740                 4    0.257192   \n",
       "1997          30942       71066           779                 3    0.471843   \n",
       "\n",
       "      ...  W_avg_mean_amount  W_avg_median_amount W_avg_count_transaction  \\\n",
       "0     ...          81.057181            71.547335               22.130350   \n",
       "1     ...          79.726211            64.614815               10.881323   \n",
       "2     ...          33.045918            31.666401               50.365759   \n",
       "3     ...         126.519642            61.903687               16.889105   \n",
       "4     ...          96.090390            87.131060               17.951362   \n",
       "...   ...                ...                  ...                     ...   \n",
       "1992  ...          15.993225            15.823071               29.737828   \n",
       "1993  ...          45.547766            40.084776               10.254864   \n",
       "1995  ...          23.130076             2.292130               22.447471   \n",
       "1996  ...          39.990010            18.858191               20.219844   \n",
       "1997  ...          30.104664             7.217393               22.801556   \n",
       "\n",
       "     M_avg_min_amount  M_avg_max_amount  M_avg_mean_amount  \\\n",
       "0            2.589153        559.207627          80.417801   \n",
       "1            2.200085        686.285932          79.696503   \n",
       "2            0.978983        412.923729          33.051507   \n",
       "3            5.520763       1576.102458         125.770742   \n",
       "4            4.826525        817.697966          96.408370   \n",
       "...               ...               ...                ...   \n",
       "1992        11.146290        248.217581          22.636976   \n",
       "1993         6.469746        325.680424          44.708037   \n",
       "1995         0.759576        538.056102          23.209078   \n",
       "1996         1.700254        470.129153          40.469902   \n",
       "1997         1.327288        397.126017          30.080759   \n",
       "\n",
       "      M_avg_median_amount  M_avg_count_transaction  \\\n",
       "0               68.428941                96.398305   \n",
       "1               66.091822                47.398305   \n",
       "2               32.344788               219.389831   \n",
       "3               58.425551                73.567797   \n",
       "4               87.651398                78.194915   \n",
       "...                   ...                      ...   \n",
       "1992            22.632258               128.064516   \n",
       "1993            39.516822                44.669492   \n",
       "1995             1.863475                97.779661   \n",
       "1996            17.507881                88.076271   \n",
       "1997             4.976441                99.322034   \n",
       "\n",
       "      monthly_evg_unique_merchants  gap_sec  \n",
       "0                        32.644068  18420.0  \n",
       "1                        28.025424  37530.0  \n",
       "2                        36.983051   7380.0  \n",
       "3                        33.559322  20040.0  \n",
       "4                        36.466102  20160.0  \n",
       "...                            ...      ...  \n",
       "1992                     23.064516   2100.0  \n",
       "1993                     22.067797  33480.0  \n",
       "1995                     18.610169  18960.0  \n",
       "1996                     32.135593  18240.0  \n",
       "1997                     29.991525  11220.0  \n",
       "\n",
       "[1219 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3600ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "num_cols = X.columns.difference(cat_cols).tolist()\n",
    "\n",
    "preprocess = ColumnTransformer([(\"num\", StandardScaler(), num_cols),\n",
    "                                (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False), cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af863e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0b16cc",
   "metadata": {},
   "source": [
    "### Logistic / RF / GB / SVM / KNN / XGBoost / LGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36551c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=5000, class_weight=\"balanced\", \n",
    "                                             solver=\"lbfgs\", random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=500, class_weight=\"balanced\", \n",
    "                                           n_jobs=-1, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM_RBF\": SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\", C=1.0, \n",
    "                   gamma=\"scale\", random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=15, weights=\"distance\"),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=1000, max_depth=10, learning_rate=0.05, subsample=0.8, \n",
    "                             colsample_bytree=0.8, objective=\"binary:logistic\", \n",
    "                             eval_metric=\"logloss\", n_jobs=-1, random_state=42),\n",
    "    \"LGBM\": LGBMClassifier(n_estimators=1000, num_leaves=63, learning_rate=0.05, subsample=0.8, \n",
    "                           colsample_bytree=0.8, class_weight=\"balanced\", n_jobs=-1, random_state=42)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c7695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ==================== LogisticRegression ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7009    0.5616    0.6236       146\n",
      "         1.0     0.4961    0.6429    0.5600        98\n",
      "\n",
      "    accuracy                         0.5943       244\n",
      "   macro avg     0.5985    0.6023    0.5918       244\n",
      "weighted avg     0.6186    0.5943    0.5980       244\n",
      "\n",
      "\n",
      " ==================== RandomForest ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6348    0.7740    0.6975       146\n",
      "         1.0     0.5000    0.3367    0.4024        98\n",
      "\n",
      "    accuracy                         0.5984       244\n",
      "   macro avg     0.5674    0.5554    0.5500       244\n",
      "weighted avg     0.5807    0.5984    0.5790       244\n",
      "\n",
      "\n",
      " ==================== GradientBoosting ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6667    0.7671    0.7134       146\n",
      "         1.0     0.5526    0.4286    0.4828        98\n",
      "\n",
      "    accuracy                         0.6311       244\n",
      "   macro avg     0.6096    0.5978    0.5981       244\n",
      "weighted avg     0.6209    0.6311    0.6208       244\n",
      "\n",
      "\n",
      " ==================== SVM_RBF ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6484    0.5685    0.6058       146\n",
      "         1.0     0.4569    0.5408    0.4953        98\n",
      "\n",
      "    accuracy                         0.5574       244\n",
      "   macro avg     0.5527    0.5547    0.5506       244\n",
      "weighted avg     0.5715    0.5574    0.5615       244\n",
      "\n",
      "\n",
      " ==================== KNN ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6289    0.6849    0.6557       146\n",
      "         1.0     0.4588    0.3980    0.4262        98\n",
      "\n",
      "    accuracy                         0.5697       244\n",
      "   macro avg     0.5439    0.5414    0.5410       244\n",
      "weighted avg     0.5606    0.5697    0.5636       244\n",
      "\n",
      "\n",
      " ==================== XGBoost ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6558    0.6918    0.6733       146\n",
      "         1.0     0.5000    0.4592    0.4787        98\n",
      "\n",
      "    accuracy                         0.5984       244\n",
      "   macro avg     0.5779    0.5755    0.5760       244\n",
      "weighted avg     0.5933    0.5984    0.5952       244\n",
      "\n",
      "\n",
      " ==================== LGBM ====================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6410    0.6849    0.6623       146\n",
      "         1.0     0.4773    0.4286    0.4516        98\n",
      "\n",
      "    accuracy                         0.5820       244\n",
      "   macro avg     0.5591    0.5568    0.5569       244\n",
      "weighted avg     0.5753    0.5820    0.5777       244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, clf in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pred = pipe.predict(X_test)\n",
    "    \n",
    "    print(\"\\n\", \"=\"*20, f\"{name}\", \"=\"*20)\n",
    "    print(classification_report(y_test, pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe3870",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05264d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8907871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": (LogisticRegression(max_iter=5000, class_weight=\"balanced\", \n",
    "                                              solver=\"lbfgs\", random_state=42),\n",
    "                          {\"clf__C\": loguniform(1e-2, 1e2)}, 25),\n",
    "    \n",
    "    \"RandomForest\": (RandomForestClassifier(class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "                    {\"clf__n_estimators\": randint(500, 1500),\n",
    "                     \"clf__max_depth\": randint(3, 30),\n",
    "                     \"clf__min_samples_split\": randint(2, 20),\n",
    "                     \"clf__min_samples_leaf\": randint(1, 10),\n",
    "                     \"clf__max_features\": [\"sqrt\", \"log2\", None]}, 35),\n",
    "                     \n",
    "    \"GradientBoosting\": (GradientBoostingClassifier(random_state=42),\n",
    "                        {\"clf__n_estimators\": randint(300, 1200),\n",
    "                         \"clf__learning_rate\": loguniform(0.01, 0.3),\n",
    "                         \"clf__max_depth\": randint(2, 6),\n",
    "                         \"clf__subsample\": uniform(0.6, 0.4),\n",
    "                         \"clf__min_samples_leaf\": randint(1, 20)}, 35),\n",
    "    \n",
    "    \"SVM_RBF\": (SVC(kernel=\"rbf\", probability=True, class_weight=\"balanced\", random_state=42),\n",
    "               {\"clf__C\": loguniform(1e-2, 1e3),\n",
    "                \"clf__gamma\": loguniform(1e-4, 1e-1)}, 30),\n",
    "    \n",
    "    \"KNN\": (KNeighborsClassifier(),\n",
    "            {\"clf__n_neighbors\": randint(3, 61),\n",
    "             \"clf__weights\": [\"uniform\", \"distance\"],\n",
    "             \"clf__p\": [1, 2]}, 30),\n",
    "\n",
    "    \"XGBoost\": (XGBClassifier(objective=\"binary:logistic\", eval_metric=\"aucpr\", n_jobs=-1, \n",
    "                              tree_method=\"hist\", random_state=42),\n",
    "               {\"clf__n_estimators\": randint(400, 1500),\n",
    "                \"clf__max_depth\": randint(3, 8),\n",
    "                \"clf__learning_rate\": loguniform(0.01, 0.2),\n",
    "                \"clf__subsample\": uniform(0.6, 0.4),\n",
    "                \"clf__colsample_bytree\": uniform(0.5, 0.5),\n",
    "                \"clf__min_child_weight\": randint(1, 10),\n",
    "                \"clf__gamma\": uniform(0.0, 5.0),\n",
    "                \"clf__reg_alpha\": loguniform(1e-8, 1e-1),\n",
    "                \"clf__reg_lambda\": loguniform(1e-3, 10.0)}, 40),\n",
    "    \n",
    "    \"LGBM\": (LGBMClassifier(objective=\"binary\", class_weight=\"balanced\", n_jobs=-1, random_state=42),\n",
    "            {\"clf__n_estimators\": randint(600, 2000),\n",
    "             \"clf__num_leaves\": randint(31, 255),\n",
    "             \"clf__learning_rate\": loguniform(0.02, 0.2),\n",
    "             \"clf__min_child_samples\": randint(10, 120),\n",
    "             \"clf__subsample\": uniform(0.6, 0.4),\n",
    "             \"clf__colsample_bytree\": uniform(0.5, 0.5),\n",
    "             \"clf__reg_lambda\": loguniform(1e-3, 10.0),\n",
    "             \"clf__reg_alpha\": loguniform(1e-8, 1e-1)}, 40)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ec1e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "===== LogisticRegression best params =====\n",
      "{'clf__C': 8.471801418819974}\n",
      "best CV F1: 0.5563\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "\n",
      "===== RandomForest best params =====\n",
      "{'clf__max_depth': 3, 'clf__max_features': 'sqrt', 'clf__min_samples_leaf': 9, 'clf__min_samples_split': 14, 'clf__n_estimators': 1244}\n",
      "best CV F1: 0.5767\n",
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n",
      "\n",
      "===== GradientBoosting best params =====\n",
      "{'clf__learning_rate': 0.0187522094557864, 'clf__max_depth': 4, 'clf__min_samples_leaf': 18, 'clf__n_estimators': 1029, 'clf__subsample': 0.7799016533479063}\n",
      "best CV F1: 0.4949\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "===== SVM_RBF best params =====\n",
      "{'clf__C': 0.33347927286375834, 'clf__gamma': 0.00019634341572933326}\n",
      "best CV F1: 0.5735\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "\n",
      "===== KNN best params =====\n",
      "{'clf__n_neighbors': 13, 'clf__p': 2, 'clf__weights': 'uniform'}\n",
      "best CV F1: 0.4887\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "===== XGBoost best params =====\n",
      "{'clf__colsample_bytree': 0.8387821809211412, 'clf__gamma': 0.08293914463928076, 'clf__learning_rate': 0.04637121010589462, 'clf__max_depth': 5, 'clf__min_child_weight': 4, 'clf__n_estimators': 1263, 'clf__reg_alpha': 4.712331753071529e-08, 'clf__reg_lambda': 5.782199315538685, 'clf__subsample': 0.759028808435009}\n",
      "best CV F1: 0.5071\n",
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "\n",
      "===== LGBM best params =====\n",
      "{'clf__colsample_bytree': 0.6838579015297168, 'clf__learning_rate': 0.036832598873490385, 'clf__min_child_samples': 119, 'clf__n_estimators': 637, 'clf__num_leaves': 139, 'clf__reg_alpha': 2.553848149194616e-05, 'clf__reg_lambda': 4.211096085003148, 'clf__subsample': 0.7737577462041715}\n",
      "best CV F1: 0.5355\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for name, (est, param_dist, n_iter) in models.items():\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", est)])\n",
    "    search = RandomizedSearchCV(estimator=pipe, param_distributions=param_dist,\n",
    "                                n_iter=n_iter, scoring=\"f1\", cv=cv, n_jobs=-1,\n",
    "                                verbose=1, random_state=42, refit=True)\n",
    "    search.fit(X_train, y_train)\n",
    "    best_models[name] = search.best_estimator_\n",
    "    print(f\"\\n===== {name} best params =====\")\n",
    "    print(f\"{search.best_params_}\")\n",
    "    print(f\"best CV F1: {search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa6893b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162f919a",
   "metadata": {},
   "source": [
    "### Bagging + OOB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e819987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score,f1_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5d047c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 X의 컬럼 순서를 기준으로 인덱스 맵 만들기\n",
    "col_order = list(X.columns)\n",
    "idx_num = [col_order.index(c) for c in num_cols]\n",
    "idx_cat = [col_order.index(c) for c in cat_cols]\n",
    "\n",
    "# 트리/배깅용: 스케일링 없이 숫자는 통과, 범주 원-핫\n",
    "prep_tree = ColumnTransformer([(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), idx_cat),\n",
    "                               (\"num\", \"passthrough\", idx_num)], remainder=\"drop\")\n",
    "\n",
    "# 선형/메타용: 숫자 스케일링 + 범주 원-핫\n",
    "prep_lin = ColumnTransformer([(\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse=True), idx_cat), \n",
    "                              (\"num\", StandardScaler(), idx_num)], remainder=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24028d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                                             ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                            sparse=True),\n",
       "                                                                              [3,\n",
       "                                                                               12,\n",
       "                                                                               13]),\n",
       "                                                                             (&#x27;num&#x27;,\n",
       "                                                                              &#x27;passthrough&#x27;,\n",
       "                                                                              [23,\n",
       "                                                                               20,\n",
       "                                                                               21,\n",
       "                                                                               22,\n",
       "                                                                               19,\n",
       "                                                                               18,\n",
       "                                                                               15,\n",
       "                                                                               16,\n",
       "                                                                               17,\n",
       "                                                                               14,\n",
       "                                                                               2,\n",
       "                                                                               9,\n",
       "                                                                               7,\n",
       "                                                                               0,\n",
       "                                                                               25,\n",
       "                                                                               24,\n",
       "                                                                               8,\n",
       "                                                                               10,\n",
       "                                                                               4,\n",
       "                                                                               1,\n",
       "                                                                               11,\n",
       "                                                                               6,\n",
       "                                                                               5])])),\n",
       "                                            (&#x27;clf&#x27;,\n",
       "                                             LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                            colsample_bytree=0.8,\n",
       "                                                            learning_rate=0.05,\n",
       "                                                            min_child_samples=50,\n",
       "                                                            n_estimators=500,\n",
       "                                                            num_leaves=100,\n",
       "                                                            objective=&#x27;binary&#x27;,\n",
       "                                                            random_state=42,\n",
       "                                                            reg_lambda=1.0,\n",
       "                                                            subsample=0.8))]),\n",
       "                  max_samples=0.8, n_estimators=30, n_jobs=-1, oob_score=True,\n",
       "                  random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                                             ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                                              OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                            sparse=True),\n",
       "                                                                              [3,\n",
       "                                                                               12,\n",
       "                                                                               13]),\n",
       "                                                                             (&#x27;num&#x27;,\n",
       "                                                                              &#x27;passthrough&#x27;,\n",
       "                                                                              [23,\n",
       "                                                                               20,\n",
       "                                                                               21,\n",
       "                                                                               22,\n",
       "                                                                               19,\n",
       "                                                                               18,\n",
       "                                                                               15,\n",
       "                                                                               16,\n",
       "                                                                               17,\n",
       "                                                                               14,\n",
       "                                                                               2,\n",
       "                                                                               9,\n",
       "                                                                               7,\n",
       "                                                                               0,\n",
       "                                                                               25,\n",
       "                                                                               24,\n",
       "                                                                               8,\n",
       "                                                                               10,\n",
       "                                                                               4,\n",
       "                                                                               1,\n",
       "                                                                               11,\n",
       "                                                                               6,\n",
       "                                                                               5])])),\n",
       "                                            (&#x27;clf&#x27;,\n",
       "                                             LGBMClassifier(class_weight=&#x27;balanced&#x27;,\n",
       "                                                            colsample_bytree=0.8,\n",
       "                                                            learning_rate=0.05,\n",
       "                                                            min_child_samples=50,\n",
       "                                                            n_estimators=500,\n",
       "                                                            num_leaves=100,\n",
       "                                                            objective=&#x27;binary&#x27;,\n",
       "                                                            random_state=42,\n",
       "                                                            reg_lambda=1.0,\n",
       "                                                            subsample=0.8))]),\n",
       "                  max_samples=0.8, n_estimators=30, n_jobs=-1, oob_score=True,\n",
       "                  random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse=True),\n",
       "                                                  [3, 12, 13]),\n",
       "                                                 (&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [23, 20, 21, 22, 19, 18, 15,\n",
       "                                                   16, 17, 14, 2, 9, 7, 0, 25,\n",
       "                                                   24, 8, 10, 4, 1, 11, 6,\n",
       "                                                   5])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.8,\n",
       "                                learning_rate=0.05, min_child_samples=50,\n",
       "                                n_estimators=500, num_leaves=100,\n",
       "                                objective=&#x27;binary&#x27;, random_state=42,\n",
       "                                reg_lambda=1.0, subsample=0.8))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                               sparse=True),\n",
       "                                 [3, 12, 13]),\n",
       "                                (&#x27;num&#x27;, &#x27;passthrough&#x27;,\n",
       "                                 [23, 20, 21, 22, 19, 18, 15, 16, 17, 14, 2, 9,\n",
       "                                  7, 0, 25, 24, 8, 10, 4, 1, 11, 6, 5])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[3, 12, 13]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse=True)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[23, 20, 21, 22, 19, 18, 15, 16, 17, 14, 2, 9, 7, 0, 25, 24, 8, 10, 4, 1, 11, 6, 5]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.8,\n",
       "               learning_rate=0.05, min_child_samples=50, n_estimators=500,\n",
       "               num_leaves=100, objective=&#x27;binary&#x27;, random_state=42,\n",
       "               reg_lambda=1.0, subsample=0.8)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=Pipeline(steps=[('prep',\n",
       "                                             ColumnTransformer(transformers=[('cat',\n",
       "                                                                              OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                            sparse=True),\n",
       "                                                                              [3,\n",
       "                                                                               12,\n",
       "                                                                               13]),\n",
       "                                                                             ('num',\n",
       "                                                                              'passthrough',\n",
       "                                                                              [23,\n",
       "                                                                               20,\n",
       "                                                                               21,\n",
       "                                                                               22,\n",
       "                                                                               19,\n",
       "                                                                               18,\n",
       "                                                                               15,\n",
       "                                                                               16,\n",
       "                                                                               17,\n",
       "                                                                               14,\n",
       "                                                                               2,\n",
       "                                                                               9,\n",
       "                                                                               7,\n",
       "                                                                               0,\n",
       "                                                                               25,\n",
       "                                                                               24,\n",
       "                                                                               8,\n",
       "                                                                               10,\n",
       "                                                                               4,\n",
       "                                                                               1,\n",
       "                                                                               11,\n",
       "                                                                               6,\n",
       "                                                                               5])])),\n",
       "                                            ('clf',\n",
       "                                             LGBMClassifier(class_weight='balanced',\n",
       "                                                            colsample_bytree=0.8,\n",
       "                                                            learning_rate=0.05,\n",
       "                                                            min_child_samples=50,\n",
       "                                                            n_estimators=500,\n",
       "                                                            num_leaves=100,\n",
       "                                                            objective='binary',\n",
       "                                                            random_state=42,\n",
       "                                                            reg_lambda=1.0,\n",
       "                                                            subsample=0.8))]),\n",
       "                  max_samples=0.8, n_estimators=30, n_jobs=-1, oob_score=True,\n",
       "                  random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_est = Pipeline([(\"prep\", prep_tree),\n",
    "                     (\"clf\", LGBMClassifier(objective=\"binary\", n_estimators=500, num_leaves=100, learning_rate=0.05, \n",
    "                                            subsample=0.8, colsample_bytree=0.8, min_child_samples=50, reg_lambda=1.0,\n",
    "                                            class_weight=\"balanced\", random_state=42, n_jobs=-1))])\n",
    "\n",
    "bag = BaggingClassifier(estimator=base_est, n_estimators=30, max_samples=0.8, bootstrap=True, \n",
    "                        oob_score=True, n_jobs=-1, random_state=42)\n",
    "\n",
    "bag.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b559fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_threshold(y_true, proba, metric=\"f1\"):\n",
    "    grid = np.linspace(0.05, 0.95, 181)\n",
    "    best_t, best = 0.5, -1\n",
    "    for t in grid:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        val = f1_score(y_true, pred) if metric==\"f1\" else None\n",
    "        if val is not None and val > best:\n",
    "            best, best_t = val, t\n",
    "    return best_t, best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d89fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OOB classification_report @ threshold = 0.50 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6663    0.7366    0.6997       729\n",
      "         1.0     0.5351    0.4510    0.4895       490\n",
      "\n",
      "    accuracy                         0.6218      1219\n",
      "   macro avg     0.6007    0.5938    0.5946      1219\n",
      "weighted avg     0.6135    0.6218    0.6152      1219\n",
      "\n",
      "\n",
      "=== OOB classification_report @ best F1 threshold = 0.195 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7625    0.3128    0.4436       729\n",
      "         1.0     0.4554    0.8551    0.5943       490\n",
      "\n",
      "    accuracy                         0.5308      1219\n",
      "   macro avg     0.6090    0.5839    0.5190      1219\n",
      "weighted avg     0.6391    0.5308    0.5042      1219\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oob_df = bag.oob_decision_function_\n",
    "oob_proba = oob_df[:, 1] if oob_df.ndim == 2 and oob_df.shape[1] == 2 else oob_df.ravel()\n",
    "y_pred = (oob_proba >= 0.5).astype(int)\n",
    "\n",
    "# (1) 임계값 0.5\n",
    "y_pred_05 = (oob_proba >= 0.5).astype(int)\n",
    "print(\"=== OOB classification_report @ threshold = 0.50 ===\")\n",
    "print(classification_report(y, y_pred_05, digits=4))\n",
    "\n",
    "# (2) OOB에서 F1 기준 최적 임계값\n",
    "thr_best, f1_best = tune_threshold(y, oob_proba, metric=\"f1\")\n",
    "y_pred_best = (oob_proba >= thr_best).astype(int)\n",
    "print(f\"\\n=== OOB classification_report @ best F1 threshold = {thr_best:.3f} ===\")\n",
    "print(classification_report(y, y_pred_best, digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
